{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb2ec35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikma\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "Episode 5019:  50%|███████████▌           | 5018/10000 [02:45<03:36, 22.99it/s, episode_reward=34, running_reward=32.9]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from Helper import LearningCurvePlot, smooth\n",
    "from actor_critic import *\n",
    "\n",
    "def average_over_repetitions(smoothing_window, plot, n_repetitions, n_episodes, learning_rate,\n",
    "                             gamma, batch_update_size, N):\n",
    "\n",
    "    reward_results = np.empty([n_repetitions,n_episodes]) # Result array\n",
    "    now = time.time()\n",
    "    \n",
    "    for rep in range(n_repetitions): # Loop over repetitions\n",
    "        rewards = cartpole(learning_rate, batch_update_size, gamma, n_episodes, N)\n",
    "        reward_results[rep] = rewards\n",
    "        \n",
    "    print('Running one setting takes {} minutes'.format((time.time()-now)/60))    \n",
    "    learning_curve = np.mean(reward_results,axis=0) # average over repetitions\n",
    "    learning_curve = smooth(learning_curve,smoothing_window) # additional smoothing\n",
    "    return learning_curve\n",
    "\n",
    "def experiment():\n",
    "    ####### Settings\n",
    "    # Experiment    \n",
    "    n_repetitions = 5\n",
    "    smoothing_window = 501\n",
    "    n_episodes = 10000\n",
    "    gamma = 0.99\n",
    "    \n",
    "    # Plotting parameters\n",
    "    plot = True\n",
    "    \n",
    "    # Nice labels for plotting\n",
    "    policy_labels = {'basesub': 'baseline subtraction',\n",
    "                  'boot': 'bootstrap', 'b+b': 'bootstrap with baseline subtraction'}       #Something here might need to be changed\n",
    "\n",
    "    \n",
    "    ####### Experiments\n",
    "    \n",
    "    good_average_reward = 250 # We set this as a benchmark of good average reward reached by the algorithm\n",
    "    \n",
    "    policy = 'boot'\n",
    "    Plot1 = LearningCurvePlot(title = 'Cartpole experiment solved with ' + policy_labels[policy])\n",
    "    Plot2 = LearningCurvePlot(title = 'Cartpole experiment solved with ' + policy_labels[policy])\n",
    "    Plot3 = LearningCurvePlot(title = 'Cartpole experiment solved with ' + policy_labels[policy])\n",
    "    lr = [0.001, 0.01, 0.1, 0.0001]\n",
    "    batch_sizes = [1, 8, 16, 24, 48]\n",
    "    N_sizes = [6, 12, 24, 48]\n",
    "    N_1 = 24\n",
    "    batch_update_size_1 = 16\n",
    "    learning_rate_1 = 0.001\n",
    "    for N in N_sizes:\n",
    "        learning_curve = average_over_repetitions(smoothing_window, plot, n_repetitions, n_episodes, learning_rate_1,\n",
    "                             gamma, batch_update_size_1, N)\n",
    "        Plot1.add_curve(learning_curve,label = 'N: ' + str(N))\n",
    "\n",
    "    Plot1.add_hline(good_average_reward, label = 'Threshold for good reward')\n",
    "    Plot1.save('cartpole_test_' + policy_labels[policy] + '_bootstrap' + '.png')\n",
    "    \n",
    "    for batch_update_size in batch_sizes:\n",
    "        learning_curve = average_over_repetitions(smoothing_window, plot, n_repetitions, n_episodes, learning_rate_1,\n",
    "                             gamma, batch_update_size, N_1)\n",
    "        Plot2.add_curve(learning_curve, label = 'batch update: ' + str(batch_update_size))\n",
    "        \n",
    "    Plot2.add_hline(good_average_reward, label = 'Threshold for good reward')\n",
    "    Plot2.save('cartpole_test_' + policy_labels[policy] + 'batch_update' + '.png')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    experiment()\n",
    "\n",
    "    \n",
    "# To run with actor_critic: change import + add N as input to average_over_repetitions + ad N as hyperparameter + change \n",
    "# number of batch sizes and learning rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9022d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
