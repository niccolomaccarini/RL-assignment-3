{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb2ec35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikma\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "Episode 9999: 100%|██████████████████████| 10000/10000 [41:04<00:00,  4.06it/s, episode_reward=500, running_reward=469]\n",
      "Episode 9999: 100%|██████████████████████| 10000/10000 [41:04<00:00,  4.06it/s, episode_reward=500, running_reward=470]\n",
      "Episode 9999: 100%|██████████████████████| 10000/10000 [40:13<00:00,  4.14it/s, episode_reward=500, running_reward=497]\n",
      "Episode 9999: 100%|██████████████████████| 10000/10000 [58:52<00:00,  2.83it/s, episode_reward=500, running_reward=496]\n",
      "Episode 9999: 100%|████████████████████| 10000/10000 [1:10:32<00:00,  2.36it/s, episode_reward=500, running_reward=468]\n",
      "  0%|                                                                                        | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running one setting takes 251.7858483393987 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 9999: 100%|██████████████████████| 10000/10000 [37:34<00:00,  4.43it/s, episode_reward=458, running_reward=490]\n",
      "Episode 9999: 100%|███████████████████████| 10000/10000 [03:23<00:00, 49.12it/s, episode_reward=9, running_reward=9.37]\n",
      "Episode 9999: 100%|███████████████████████| 10000/10000 [03:34<00:00, 46.64it/s, episode_reward=9, running_reward=9.36]\n",
      "Episode 9999: 100%|███████████████████████| 10000/10000 [04:32<00:00, 36.71it/s, episode_reward=9, running_reward=9.45]\n",
      "Episode 9999: 100%|██████████████████████| 10000/10000 [04:00<00:00, 41.50it/s, episode_reward=10, running_reward=9.45]\n",
      "  0%|                                                                                        | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running one setting takes 53.108317069212596 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 9999: 100%|███████████████████████| 10000/10000 [03:11<00:00, 52.32it/s, episode_reward=8, running_reward=9.35]\n",
      "Episode 9999: 100%|██████████████████████| 10000/10000 [03:03<00:00, 54.60it/s, episode_reward=10, running_reward=9.36]\n",
      "Episode 9999: 100%|██████████████████████| 10000/10000 [03:04<00:00, 54.24it/s, episode_reward=10, running_reward=9.35]\n",
      "Episode 9999: 100%|███████████████████████| 10000/10000 [05:04<00:00, 32.79it/s, episode_reward=9, running_reward=9.36]\n",
      "Episode 9999: 100%|███████████████████████| 10000/10000 [03:09<00:00, 52.78it/s, episode_reward=9, running_reward=9.31]\n",
      "  0%|                                                                                        | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running one setting takes 17.554421857992807 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 9999: 100%|██████████████████████| 10000/10000 [23:24<00:00,  7.12it/s, episode_reward=500, running_reward=294]\n",
      "Episode 9999: 100%|██████████████████████| 10000/10000 [09:41<00:00, 17.19it/s, episode_reward=131, running_reward=110]\n",
      "Episode 9567:  96%|██████████████████████ | 9568/10000 [11:29<01:02,  6.95it/s, episode_reward=161, running_reward=143]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from Helper import LearningCurvePlot, smooth\n",
    "from baseline_subtraction import *\n",
    "\n",
    "def average_over_repetitions(smoothing_window, plot, n_repetitions, n_episodes, learning_rate,\n",
    "                             gamma, batch_update_size):\n",
    "\n",
    "    reward_results = np.empty([n_repetitions,n_episodes]) # Result array\n",
    "    now = time.time()\n",
    "    \n",
    "    for rep in range(n_repetitions): # Loop over repetitions\n",
    "        rewards = cartpole(learning_rate, batch_update_size, gamma)\n",
    "        reward_results[rep] = rewards\n",
    "        \n",
    "    print('Running one setting takes {} minutes'.format((time.time()-now)/60))    \n",
    "    learning_curve = np.mean(reward_results,axis=0) # average over repetitions\n",
    "    learning_curve = smooth(learning_curve,smoothing_window) # additional smoothing\n",
    "    return learning_curve\n",
    "\n",
    "def experiment():\n",
    "    ####### Settings\n",
    "    # Experiment    \n",
    "    n_repetitions = 5\n",
    "    smoothing_window = 1001\n",
    "    n_episodes = 10000\n",
    "    gamma = 0.99\n",
    "    \n",
    "    # Plotting parameters\n",
    "    plot = True\n",
    "    \n",
    "    # Nice labels for plotting\n",
    "    policy_labels = {'basesub': 'baseline subtraction',\n",
    "                  'boot': 'bootstrap', 'b+b': 'bootstrap with baseline subtraction'}       #Something here might need to be changed\n",
    "\n",
    "    \n",
    "    ####### Experiments\n",
    "    \n",
    "    good_average_reward = 250 # We set this as a benchmark of good average reward reached by the algorithm\n",
    "    \n",
    "    policy = 'basesub'\n",
    "    Plot = LearningCurvePlot(title = 'Cartpole experiment solved with' + policy_labels[policy])\n",
    "    lr = [0.001, 0.01, 0.1, 0.0001]\n",
    "    batch_sizes = [1,8,16,24]\n",
    "    batch_update_size_1 = 1\n",
    "    for learning_rate in lr:\n",
    "        learning_curve = average_over_repetitions(smoothing_window, plot, n_repetitions, n_episodes, learning_rate,\n",
    "                             gamma, batch_update_size_1)\n",
    "        Plot.add_curve(learning_curve,label=policy_labels[policy] + ', learning rate: ' + str(learning_rate))\n",
    "\n",
    "    Plot.add_hline(optimal_average_reward_per_timestep)\n",
    "    Plot.save('cartpole_test' + policy_labels[policy] + 'learning_rate' + '.png')\n",
    "    \n",
    "    for batch_update_size in batch_sizes:\n",
    "        learning_rate_1 = 0.001\n",
    "        learning_curve = average_over_repetitions(smoothing_window, plot, n_repetitions, n_episodes, learning_rate_1,\n",
    "                             gamma, batch_update_size)\n",
    "        Plot.add_curve(learning_curve,label=policy_labels[policy] + ', batch update: ' + str(batch_update_size))\n",
    "        \n",
    "    Plot.add_hline(good_average_reward)\n",
    "    Plot.save('cartpole_test' + policy_labels[policy] + 'batch_update' + '.png')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    experiment()\n",
    "\n",
    "    \n",
    "# To run with actor_critic: change import + add N as input to average_over_repetitions + ad N as hyperparameter + change \n",
    "# number of batch sizes and learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c9d2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
